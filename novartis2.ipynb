{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Novartis Competetion\n",
    "\n",
    "In this competition we have to predict if the server is going to be hacked or not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import seaborn as sns\n",
    "# Stats\n",
    "from scipy import stats\n",
    "from scipy.stats import skew, norm\n",
    "from scipy.special import boxcox1p\n",
    "from scipy.stats import boxcox_normmax\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing all the given datasets to pandas dataframes\n",
    "train = pd.read_csv(\"train.csv\")\n",
    "test = pd.read_csv(\"test.csv\")\n",
    "\n",
    "# Parsing the date column as 'date' datatype in both training and test data\n",
    "train['DATE'] = pd.to_datetime(train['DATE'])\n",
    "test['DATE'] = pd.to_datetime(test['DATE'])\n",
    "\n",
    "sub = pd.read_csv(\"sample_submission.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory data analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>INCIDENT_ID</th>\n",
       "      <th>DATE</th>\n",
       "      <th>X_1</th>\n",
       "      <th>X_2</th>\n",
       "      <th>X_3</th>\n",
       "      <th>X_4</th>\n",
       "      <th>X_5</th>\n",
       "      <th>X_6</th>\n",
       "      <th>X_7</th>\n",
       "      <th>X_8</th>\n",
       "      <th>X_9</th>\n",
       "      <th>X_10</th>\n",
       "      <th>X_11</th>\n",
       "      <th>X_12</th>\n",
       "      <th>X_13</th>\n",
       "      <th>X_14</th>\n",
       "      <th>X_15</th>\n",
       "      <th>MULTIPLE_OFFENSE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CR_102659</td>\n",
       "      <td>2004-07-04</td>\n",
       "      <td>0</td>\n",
       "      <td>36</td>\n",
       "      <td>34</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>174</td>\n",
       "      <td>1.0</td>\n",
       "      <td>92</td>\n",
       "      <td>29</td>\n",
       "      <td>36</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CR_189752</td>\n",
       "      <td>2017-07-18</td>\n",
       "      <td>1</td>\n",
       "      <td>37</td>\n",
       "      <td>37</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>236</td>\n",
       "      <td>1.0</td>\n",
       "      <td>103</td>\n",
       "      <td>142</td>\n",
       "      <td>34</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CR_184637</td>\n",
       "      <td>2017-03-15</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>174</td>\n",
       "      <td>1.0</td>\n",
       "      <td>110</td>\n",
       "      <td>93</td>\n",
       "      <td>34</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CR_139071</td>\n",
       "      <td>2009-02-13</td>\n",
       "      <td>0</td>\n",
       "      <td>33</td>\n",
       "      <td>32</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>249</td>\n",
       "      <td>1.0</td>\n",
       "      <td>72</td>\n",
       "      <td>29</td>\n",
       "      <td>34</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CR_109335</td>\n",
       "      <td>2005-04-13</td>\n",
       "      <td>0</td>\n",
       "      <td>33</td>\n",
       "      <td>32</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>174</td>\n",
       "      <td>0.0</td>\n",
       "      <td>112</td>\n",
       "      <td>29</td>\n",
       "      <td>43</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  INCIDENT_ID       DATE  X_1  X_2  X_3  X_4  X_5  X_6  X_7  X_8  X_9  X_10  \\\n",
       "0   CR_102659 2004-07-04    0   36   34    2    1    5    6    1    6     1   \n",
       "1   CR_189752 2017-07-18    1   37   37    0    0   11   17    1    6     1   \n",
       "2   CR_184637 2017-03-15    0    3    2    3    5    1    0    2    3     1   \n",
       "3   CR_139071 2009-02-13    0   33   32    2    1    7    1    1    6     1   \n",
       "4   CR_109335 2005-04-13    0   33   32    2    1    8    3    0    5     1   \n",
       "\n",
       "   X_11  X_12  X_13  X_14  X_15  MULTIPLE_OFFENSE  \n",
       "0   174   1.0    92    29    36                 0  \n",
       "1   236   1.0   103   142    34                 1  \n",
       "2   174   1.0   110    93    34                 1  \n",
       "3   249   1.0    72    29    34                 1  \n",
       "4   174   0.0   112    29    43                 1  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking the training data\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the initial look we can see that all the encrypted values are numerical values, we may need to further check if some columns are categorical and are encoded to numerical values.<br>\n",
    "\n",
    "Also only variable X_12 is float whereas all other features are integers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X_1</th>\n",
       "      <th>X_2</th>\n",
       "      <th>X_3</th>\n",
       "      <th>X_4</th>\n",
       "      <th>X_5</th>\n",
       "      <th>X_6</th>\n",
       "      <th>X_7</th>\n",
       "      <th>X_8</th>\n",
       "      <th>X_9</th>\n",
       "      <th>X_10</th>\n",
       "      <th>X_11</th>\n",
       "      <th>X_12</th>\n",
       "      <th>X_13</th>\n",
       "      <th>X_14</th>\n",
       "      <th>X_15</th>\n",
       "      <th>MULTIPLE_OFFENSE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>23856.000000</td>\n",
       "      <td>23856.000000</td>\n",
       "      <td>23856.000000</td>\n",
       "      <td>23856.000000</td>\n",
       "      <td>23856.000000</td>\n",
       "      <td>23856.000000</td>\n",
       "      <td>23856.000000</td>\n",
       "      <td>23856.000000</td>\n",
       "      <td>23856.000000</td>\n",
       "      <td>23856.000000</td>\n",
       "      <td>23856.000000</td>\n",
       "      <td>23674.000000</td>\n",
       "      <td>23856.000000</td>\n",
       "      <td>23856.000000</td>\n",
       "      <td>23856.000000</td>\n",
       "      <td>23856.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.483778</td>\n",
       "      <td>24.791206</td>\n",
       "      <td>24.637450</td>\n",
       "      <td>4.276744</td>\n",
       "      <td>2.455609</td>\n",
       "      <td>6.154175</td>\n",
       "      <td>4.876509</td>\n",
       "      <td>0.972460</td>\n",
       "      <td>4.924128</td>\n",
       "      <td>1.244802</td>\n",
       "      <td>206.954519</td>\n",
       "      <td>0.974064</td>\n",
       "      <td>85.237383</td>\n",
       "      <td>72.674296</td>\n",
       "      <td>33.464747</td>\n",
       "      <td>0.955231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.439738</td>\n",
       "      <td>15.240231</td>\n",
       "      <td>15.135093</td>\n",
       "      <td>2.944672</td>\n",
       "      <td>1.963095</td>\n",
       "      <td>4.471756</td>\n",
       "      <td>3.881931</td>\n",
       "      <td>1.453144</td>\n",
       "      <td>1.362625</td>\n",
       "      <td>1.119301</td>\n",
       "      <td>93.033348</td>\n",
       "      <td>1.167725</td>\n",
       "      <td>27.597226</td>\n",
       "      <td>43.297320</td>\n",
       "      <td>8.386834</td>\n",
       "      <td>0.206800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>174.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>72.000000</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>34.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>249.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>98.000000</td>\n",
       "      <td>62.000000</td>\n",
       "      <td>34.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>249.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>103.000000</td>\n",
       "      <td>107.000000</td>\n",
       "      <td>34.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>7.000000</td>\n",
       "      <td>52.000000</td>\n",
       "      <td>52.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>90.000000</td>\n",
       "      <td>332.000000</td>\n",
       "      <td>90.000000</td>\n",
       "      <td>116.000000</td>\n",
       "      <td>142.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                X_1           X_2           X_3           X_4           X_5  \\\n",
       "count  23856.000000  23856.000000  23856.000000  23856.000000  23856.000000   \n",
       "mean       0.483778     24.791206     24.637450      4.276744      2.455609   \n",
       "std        1.439738     15.240231     15.135093      2.944672      1.963095   \n",
       "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%        0.000000      7.000000      8.000000      2.000000      1.000000   \n",
       "50%        0.000000     24.000000     24.000000      4.000000      3.000000   \n",
       "75%        0.000000     36.000000     35.000000      6.000000      5.000000   \n",
       "max        7.000000     52.000000     52.000000     10.000000      5.000000   \n",
       "\n",
       "                X_6           X_7           X_8           X_9          X_10  \\\n",
       "count  23856.000000  23856.000000  23856.000000  23856.000000  23856.000000   \n",
       "mean       6.154175      4.876509      0.972460      4.924128      1.244802   \n",
       "std        4.471756      3.881931      1.453144      1.362625      1.119301   \n",
       "min        1.000000      0.000000      0.000000      0.000000      1.000000   \n",
       "25%        3.000000      2.000000      0.000000      5.000000      1.000000   \n",
       "50%        5.000000      4.000000      1.000000      5.000000      1.000000   \n",
       "75%        8.000000      7.000000      1.000000      6.000000      1.000000   \n",
       "max       19.000000     18.000000     99.000000      6.000000     90.000000   \n",
       "\n",
       "               X_11          X_12          X_13          X_14          X_15  \\\n",
       "count  23856.000000  23674.000000  23856.000000  23856.000000  23856.000000   \n",
       "mean     206.954519      0.974064     85.237383     72.674296     33.464747   \n",
       "std       93.033348      1.167725     27.597226     43.297320      8.386834   \n",
       "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%      174.000000      1.000000     72.000000     29.000000     34.000000   \n",
       "50%      249.000000      1.000000     98.000000     62.000000     34.000000   \n",
       "75%      249.000000      1.000000    103.000000    107.000000     34.000000   \n",
       "max      332.000000     90.000000    116.000000    142.000000     50.000000   \n",
       "\n",
       "       MULTIPLE_OFFENSE  \n",
       "count      23856.000000  \n",
       "mean           0.955231  \n",
       "std            0.206800  \n",
       "min            0.000000  \n",
       "25%            1.000000  \n",
       "50%            1.000000  \n",
       "75%            1.000000  \n",
       "max            1.000000  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking the null values in the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "X_12                182\n",
       "MULTIPLE_OFFENSE      0\n",
       "X_6                   0\n",
       "DATE                  0\n",
       "X_1                   0\n",
       "X_2                   0\n",
       "X_3                   0\n",
       "X_4                   0\n",
       "X_5                   0\n",
       "X_7                   0\n",
       "X_15                  0\n",
       "X_8                   0\n",
       "X_9                   0\n",
       "X_10                  0\n",
       "X_11                  0\n",
       "X_13                  0\n",
       "X_14                  0\n",
       "INCIDENT_ID           0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.isna().sum().sort_values(ascending = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Variable X_12 is the only feature having null values present in the data, lets check the values in X_12 variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0     15674\n",
       "0.0      5171\n",
       "2.0      2039\n",
       "3.0       476\n",
       "4.0       176\n",
       "5.0        59\n",
       "6.0        36\n",
       "8.0         9\n",
       "10.0        7\n",
       "9.0         6\n",
       "7.0         4\n",
       "11.0        4\n",
       "15.0        2\n",
       "20.0        2\n",
       "17.0        1\n",
       "58.0        1\n",
       "50.0        1\n",
       "40.0        1\n",
       "16.0        1\n",
       "90.0        1\n",
       "12.0        1\n",
       "30.0        1\n",
       "14.0        1\n",
       "Name: X_12, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['X_12'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data in variable X_12 seems to be skewed hence to fill the null values in a skewed distribution is done by either filling the null values with median or mode.\n",
    "\n",
    "I will be filling the null values with the mode value i.e. 1\n",
    "\n",
    "Also all the values are having only 0 after the decimal, hence this variable can be converted to integer column without any precision or data loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filling the null values with 1\n",
    "train = train.fillna(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Changing the data type of X_12 variable from Float to Integer for saving memmory and computation\n",
    "train['X_12'] = train['X_12'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MULTIPLE_OFFENSE    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking is any null value is pending to be treated in the dataset\n",
    "train.isna().sum().sort_values(ascending = False).head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "INCIDENT_ID      0\n",
       "DATE             0\n",
       "X_1              0\n",
       "X_2              0\n",
       "X_3              0\n",
       "X_4              0\n",
       "X_5              0\n",
       "X_6              0\n",
       "X_7              0\n",
       "X_8              0\n",
       "X_9              0\n",
       "X_10             0\n",
       "X_11             0\n",
       "X_12           127\n",
       "X_13             0\n",
       "X_14             0\n",
       "X_15             0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filling Na values in test set also with the mean value of X_12 variable i.e. '1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = test.fillna(1)\n",
    "test['X_12'] = test['X_12'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "X_15    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking if any null value is pending the test dataset to be treated before we begin further analysis\n",
    "test.isna().sum().sort_values(ascending = False).head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking the target variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    22788\n",
       "0     1068\n",
       "Name: MULTIPLE_OFFENSE, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['MULTIPLE_OFFENSE'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "ax = sns.countplot(x=\"MULTIPLE_OFFENSE\",data=train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The target variable is highly biased and may cause problems in predicting the values, hence we should apply techniques like stratified sampling, SMOTE etc. for proper sampling in the training data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking if there is any duplicate column present in the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tushar\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1885cc73604f452ab259290d902993cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=18.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import tqdm\n",
    "train_enc = pd.DataFrame(index = train.index)\n",
    "for col in tqdm.tqdm_notebook(train.columns):\n",
    "    train_enc[col] = train[col].factorize()[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are no duplicates in the given data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking the skewness of the features given in the training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['X_1', 'X_2', 'X_3', 'X_4', 'X_5', 'X_6', 'X_7', 'X_8', 'X_9', 'X_10',\n",
       "       'X_11', 'X_12', 'X_13', 'X_14', 'X_15', 'MULTIPLE_OFFENSE'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_names = train.columns[2:]\n",
    "feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 6 numerical features with Skew > 0.5 :\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "X_10    34.940516\n",
       "X_12    30.733923\n",
       "X_8     17.702736\n",
       "X_1      3.789069\n",
       "X_6      0.960769\n",
       "X_7      0.796118\n",
       "X_14     0.245572\n",
       "X_4      0.183382\n",
       "X_5      0.175220\n",
       "X_3     -0.082115\n",
       "dtype: float64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find skewed numerical features\n",
    "skew_features = train[feature_names].apply(lambda x: skew(x)).sort_values(ascending=False)\n",
    "\n",
    "# Features with high skewness\n",
    "high_skew = skew_features[skew_features > 0.5]\n",
    "skew_index = high_skew.index\n",
    "\n",
    "print(\"There are {} numerical features with Skew > 0.5 :\".format(high_skew.shape[0]))\n",
    "skewness = pd.DataFrame({'Skew' :high_skew})\n",
    "skew_features.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking Outliers in the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([   32,    47,    47, ..., 23825, 23849, 23855], dtype=int64), array([ 0,  9, 11, ...,  7,  0,  0], dtype=int64))\n"
     ]
    }
   ],
   "source": [
    "# Dropping ID and target columns\n",
    "z_score_calc = train.drop(columns=['INCIDENT_ID', 'DATE','MULTIPLE_OFFENSE'])\n",
    "# Calculating z score\n",
    "z = np.abs(stats.zscore(z_score_calc))\n",
    "# print(z)\n",
    "threshold = 3\n",
    "print(np.where(z > 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "treated_data = train[(z < 5).all(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before treating outliers : (23856, 18)\n",
      "after treating outliers : (23713, 18)\n"
     ]
    }
   ],
   "source": [
    "print(\"before treating outliers : {}\".format(train.shape))\n",
    "print(\"after treating outliers : {}\".format(treated_data.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the variables for model fitting\n",
    "X = treated_data.drop(columns=['INCIDENT_ID', 'DATE','MULTIPLE_OFFENSE'])\n",
    "y = treated_data['MULTIPLE_OFFENSE']\n",
    "\n",
    "# Test variable\n",
    "test = test.drop(columns=['DATE','INCIDENT_ID'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,test_size = .3, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting imblearn\n",
      "  Downloading imblearn-0.0-py2.py3-none-any.whl (1.9 kB)\n",
      "Collecting imbalanced-learn\n",
      "  Downloading imbalanced_learn-0.6.2-py3-none-any.whl (163 kB)\n",
      "Requirement already satisfied: numpy>=1.11 in c:\\users\\tushar\\anaconda3\\lib\\site-packages (from imbalanced-learn->imblearn) (1.18.1)\n",
      "Requirement already satisfied: scipy>=0.17 in c:\\users\\tushar\\anaconda3\\lib\\site-packages (from imbalanced-learn->imblearn) (1.4.1)\n",
      "Requirement already satisfied: scikit-learn>=0.22 in c:\\users\\tushar\\anaconda3\\lib\\site-packages (from imbalanced-learn->imblearn) (0.22.1)\n",
      "Requirement already satisfied: joblib>=0.11 in c:\\users\\tushar\\anaconda3\\lib\\site-packages (from imbalanced-learn->imblearn) (0.14.1)\n",
      "Installing collected packages: imbalanced-learn, imblearn\n",
      "Successfully installed imbalanced-learn-0.6.2 imblearn-0.0\n"
     ]
    }
   ],
   "source": [
    "!pip install imblearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before OverSampling, counts of label '1': 15865\n",
      "Before OverSampling, counts of label '0': 734 \n",
      "\n",
      "After OverSampling, the shape of train_X: (31730, 15)\n",
      "After OverSampling, the shape of train_y: (31730,) \n",
      "\n",
      "After OverSampling, counts of label '1': 15865\n",
      "After OverSampling, counts of label '0': 15865\n"
     ]
    }
   ],
   "source": [
    "print(\"Before OverSampling, counts of label '1': {}\".format(sum(y_train == 1))) \n",
    "print(\"Before OverSampling, counts of label '0': {} \\n\".format(sum(y_train == 0))) \n",
    "  \n",
    "# import SMOTE module from imblearn library \n",
    "# pip install imblearn (if you don't have imblearn in your system) \n",
    "from imblearn.over_sampling import SMOTE \n",
    "sm = SMOTE(random_state = 2) \n",
    "X_train_res, y_train_res = sm.fit_sample(X_train, y_train.ravel()) \n",
    "  \n",
    "print('After OverSampling, the shape of train_X: {}'.format(X_train_res.shape)) \n",
    "print('After OverSampling, the shape of train_y: {} \\n'.format(y_train_res.shape)) \n",
    "  \n",
    "print(\"After OverSampling, counts of label '1': {}\".format(sum(y_train_res == 1))) \n",
    "print(\"After OverSampling, counts of label '0': {}\".format(sum(y_train_res == 0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9912847905538376"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Import the random forest model.\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "## This line instantiates the model. \n",
    "rf = RandomForestClassifier() \n",
    "## Fit the model on your training data.\n",
    "rf.fit(X_train, y_train) \n",
    "## And score it on your testing data.\n",
    "rf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9942367163339894"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## This line instantiates the model. \n",
    "rf2 = RandomForestClassifier() \n",
    "## Fit the model on your training data.\n",
    "rf2.fit(X_train_res, y_train_res) \n",
    "## And score it on your testing data.\n",
    "rf2.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_rf = rf.predict(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_rf2 = rf2.predict(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filling the prediction values agains the Incident'id's of the test data \n",
    "# to create final submission file\n",
    "test_orig = pd.read_csv(\"test.csv\")\n",
    "submission=pd.DataFrame({\"INCIDENT_ID\":test_orig['INCIDENT_ID'],\n",
    "                         \"MULTIPLE_OFFENSE\":prediction_rf})\n",
    "\n",
    "# Writing the submission dataframe to a csv file to submit\n",
    "submission.to_csv('submission_rf.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filling the prediction values agains the Incident'id's of the test data \n",
    "# to create final submission file\n",
    "test_orig = pd.read_csv(\"test.csv\")\n",
    "submission=pd.DataFrame({\"INCIDENT_ID\":test_orig['INCIDENT_ID'],\n",
    "                         \"MULTIPLE_OFFENSE\":prediction_rf2})\n",
    "\n",
    "# Writing the submission dataframe to a csv file to submit\n",
    "submission.to_csv('submission_rf2.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting lightgbm\n",
      "  Downloading lightgbm-2.3.1-py2.py3-none-win_amd64.whl (544 kB)\n",
      "Requirement already satisfied: numpy in c:\\users\\tushar\\anaconda3\\lib\\site-packages (from lightgbm) (1.18.1)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\tushar\\anaconda3\\lib\\site-packages (from lightgbm) (0.22.1)\n",
      "Requirement already satisfied: scipy in c:\\users\\tushar\\anaconda3\\lib\\site-packages (from lightgbm) (1.4.1)\n",
      "Requirement already satisfied: joblib>=0.11 in c:\\users\\tushar\\anaconda3\\lib\\site-packages (from scikit-learn->lightgbm) (0.14.1)\n",
      "Installing collected packages: lightgbm\n",
      "Successfully installed lightgbm-2.3.1\n"
     ]
    }
   ],
   "source": [
    "!pip install lightgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9983131852684847"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import lightgbm as lgb\n",
    "lgbc = lgb.LGBMClassifier(learning_rate = 0.125, metric = 'l1', \n",
    "                        n_estimators = 20, num_leaves = 38)\n",
    "lgbc.fit(X_train, y_train) \n",
    "lgbc.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9974697779027271"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lgbc2 = lgb.LGBMClassifier(learning_rate = 0.125, metric = 'l1', \n",
    "                        n_estimators = 20, num_leaves = 38)\n",
    "lgbc2.fit(X_train_res, y_train_res) \n",
    "lgbc2.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_lgb = lgbc.predict(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_lgbc2 = lgbc2.predict(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filling the prediction values agains the Incident'id's of the test data \n",
    "# to create final submission file\n",
    "test_orig = pd.read_csv(\"test.csv\")\n",
    "submission=pd.DataFrame({\"INCIDENT_ID\":test_orig['INCIDENT_ID'],\n",
    "                         \"MULTIPLE_OFFENSE\":prediction_lgb})\n",
    "\n",
    "# Writing the submission dataframe to a csv file to submit\n",
    "submission.to_csv('submission_lgb.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filling the prediction values agains the Incident'id's of the test data \n",
    "# to create final submission file\n",
    "test_orig = pd.read_csv(\"test.csv\")\n",
    "submission=pd.DataFrame({\"INCIDENT_ID\":test_orig['INCIDENT_ID'],\n",
    "                         \"MULTIPLE_OFFENSE\":prediction_lgbc2})\n",
    "\n",
    "# Writing the submission dataframe to a csv file to submit\n",
    "submission.to_csv('submission_lgb2.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting xgboost\n",
      "  Downloading xgboost-1.1.0-py3-none-win_amd64.whl (37.7 MB)\n",
      "Requirement already satisfied: numpy in c:\\users\\tushar\\anaconda3\\lib\\site-packages (from xgboost) (1.18.1)\n",
      "Requirement already satisfied: scipy in c:\\users\\tushar\\anaconda3\\lib\\site-packages (from xgboost) (1.4.1)\n",
      "Installing collected packages: xgboost\n",
      "Successfully installed xgboost-1.1.0\n"
     ]
    }
   ],
   "source": [
    "!pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9992971605285352"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "xgbc = xgb.XGBClassifier()\n",
    "xgbc.fit(X_train, y_train) \n",
    "xgbc.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_xgb = xgbc.predict(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9985943210570706"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgbc2 = xgb.XGBClassifier()\n",
    "xgbc2.fit(X_train_res, y_train_res) \n",
    "xgbc2.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_xgb2 = xgbc2.predict(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filling the prediction values agains the Incident'id's of the test data \n",
    "# to create final submission file\n",
    "test_orig = pd.read_csv(\"test.csv\")\n",
    "submission=pd.DataFrame({\"INCIDENT_ID\":test_orig['INCIDENT_ID'],\n",
    "                         \"MULTIPLE_OFFENSE\":prediction_xgb})\n",
    "\n",
    "# Writing the submission dataframe to a csv file to submit\n",
    "submission.to_csv('submission_xgb.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filling the prediction values agains the Incident'id's of the test data \n",
    "# to create final submission file\n",
    "test_orig = pd.read_csv(\"test.csv\")\n",
    "submission=pd.DataFrame({\"INCIDENT_ID\":test_orig['INCIDENT_ID'],\n",
    "                         \"MULTIPLE_OFFENSE\":prediction_xgb2})\n",
    "\n",
    "# Writing the submission dataframe to a csv file to submit\n",
    "submission.to_csv('submission_xgb2.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
